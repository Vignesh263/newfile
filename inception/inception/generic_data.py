# Copyright 2016 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""Generic data set for data generated using data/build_image_data.py 
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
FLAGS = tf.app.flags.FLAGS

from inception.dataset import Dataset


class GenericData(Dataset):
  """Generic data set.
    It loads the data set generated by data/build_image_data.py
    output directory.
   """

  def __init__(self, subset):
    super(GenericData, self).__init__('GenericData', subset)
    training_data_files = self.data_files() # also load test
    label_count, sample_count_train, sample_count_validation = self._deserialize_metadata(FLAGS.data_dir)
    print(label_count, sample_count_train, sample_count_validation)
    self.__num_classes_in_dataset = label_count
    self.__sample_count_in_subset = {}
    self.__sample_count_in_subset['train'] = sample_count_train
    self.__sample_count_in_subset['validation'] = sample_count_validation

  def _deserialize_metadata(self, data_dir):
    with tf.Session() as sess:
        metadataFilePath = '%s/metadata' % (data_dir)
        filename_queue = tf.train.string_input_producer([metadataFilePath])
        key, value = self.reader().read(filename_queue)
        readRecord = tf.parse_single_example(
            value,
            features={"label_count": tf.FixedLenFeature([1], tf.int64),
            "sample_count/train": tf.FixedLenFeature([1], tf.int64),
            "sample_count/validation": tf.FixedLenFeature([1], tf.int64)
            })
        label_count = tf.cast(readRecord['label_count'], dtype=tf.int64)
        sample_count_train = tf.cast(readRecord['sample_count/train'], dtype=tf.int64)
        sample_count_validation = tf.cast(readRecord['sample_count/validation'], dtype=tf.int64)
        label_count_shuffle, sample_count_train_shuffle, sample_count_validation_shuffle = tf.train.shuffle_batch(
            [label_count, sample_count_train, sample_count_validation], batch_size=1, num_threads=1,
            capacity=1,
            min_after_dequeue=0)
        init_op = tf.group(tf.initialize_all_variables(),
            tf.initialize_local_variables())
        sess.run(init_op)
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(sess=sess, coord=coord)
        label_count_result, sample_count_train_result, sample_count_validation_result = sess.run([label_count_shuffle, sample_count_train_shuffle, sample_count_validation_shuffle])
        coord.request_stop()
        coord.join(threads)
        return label_count_result[0][0], sample_count_train_result[0][0], sample_count_validation_result[0][0]


  def num_classes(self):
    """Returns the number of classes in the data set."""
    return self.__num_classes_in_dataset

  def num_examples_per_epoch(self):
    """Returns the number of examples in the data subset."""
    return self.__sample_count_in_subset[self.subset]

  def download_message(self):
    """Instruction to set up a generic data set."""

    print('Failed to locate generic data in folder %s'% self.__data_folder)
    print('')
    print('The generic dataset expects data to be placed in folder %s.'
          'You have to do that yourself, and make sure it has the following folder structure '
          ' train/<> TODO:: explain this location of the sharded TFRecords.\n')
    print('Please see README.md for instructions on how to build '
          'a generic dataset.\n')
