{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_estimator.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IjJfzgc2uq2s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "metadata": {
        "id": "kDjprFiEuwXE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJF_WtTZvAyL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title MIT License { display-mode: \"form\" }\n",
        "#\n",
        "# Copyright (c) 2018 Dr. Kashif Rasul\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "veIFyHNgvt18",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Estimators and multi-GPUs with tf.keras, tf.data, and eager execution"
      ]
    },
    {
      "metadata": {
        "id": "kHT-DcAyveNk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/estimators/keras-estimator\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/models/blob/master/samples/core/tutorials/estimators/keras-estimator.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/samples/core/tutorials/estimators/keras-estimator.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "Z1ixcW4huOcJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The [Estimators](https://www.tensorflow.org/guide/estimators) API is used for training models in a distributed enviornment such as on nodes with multiple GPUs or on many nodes with GPUs etc. This is particularly useful when training on huge datasets. But we will however present the API for the tiny Fashion-MNIST dataset as usual in the interest of time.\n",
        "\n",
        "Essentially what we want to remember is that a `tf.keras.Model` can be trained with `tf.estimator` API by converting it to `tf.estimator.Estimator` object via the `tf.keras.estimator.model_to_estimator` method. Once converted we can apply the machinery of the `Estimator` to train on different hardware configurations."
      ]
    },
    {
      "metadata": {
        "id": "jSAy1sL_wOud",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U tf-nightly-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ipn2YvZwuOcL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uCR6QwEnxZmQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "metadata": {
        "id": "7K9QZv3huOcO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CflLMaJCuOcQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TRAINING_SIZE = len(train_images)\n",
        "TEST_SIZE = len(test_images)\n",
        "\n",
        "train_images = np.asarray(train_images, dtype=np.float32) / 255\n",
        "\n",
        "# Convert the train images and add channels\n",
        "train_images = train_images.reshape((TRAINING_SIZE, 28, 28, 1))\n",
        "\n",
        "test_images = np.asarray(test_images, dtype=np.float32) / 255\n",
        "# Convert the train images and add channels\n",
        "test_images = test_images.reshape((TEST_SIZE, 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FjZSl-0suOcU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# How many categories we are predicting from (0-9)\n",
        "LABEL_DIMENSIONS = 10\n",
        "\n",
        "train_labels  = tf.keras.utils.to_categorical(train_labels, LABEL_DIMENSIONS)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, LABEL_DIMENSIONS)\n",
        "\n",
        "# Cast the labels to floats, needed later\n",
        "train_labels = train_labels.astype(np.float32)\n",
        "test_labels = test_labels.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "afe3acUfxdXe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build a Keras model"
      ]
    },
    {
      "metadata": {
        "id": "fUEnSRWDuOcV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(28,28,1))  # Returns a placeholder tensor\n",
        "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.nn.relu)(inputs)\n",
        "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu)(x)\n",
        "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu)(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(64, activation=tf.nn.relu)(x)\n",
        "predictions = tf.keras.layers.Dense(LABEL_DIMENSIONS, activation=tf.nn.softmax)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ZT99khluOcY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=inputs, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IUMvLqnhuOca",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ciL5oGupxqzE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create an Estimator"
      ]
    },
    {
      "metadata": {
        "id": "wVOcUxTJuOcd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now to create an Estimator from the compiled Keras model we call the `model_to_estimator` method. Note that the initial model state of the keras model is preserved in the created Estimator.\n",
        "\n",
        "So what's so good about Estimators? Well to start off with:\n",
        "\n",
        "* you can run Estimator-based models on a local host or an a distributed multi-GPU environment without changing your model\n",
        "* Estimators simplify sharing implementations between model developers\n",
        "* Estimators build the graph for you\n",
        "\n",
        "\n",
        "So how do we go about training our simple `tf.keras` model to use multi-GPUs? Well we can use the `tf.contrib.MirroredStrategy` paradigm which does in-graph replication with synchronous training. To use this we first create an estimator from the `tf.keras` model and give it the `MirroredStrategy` configuration via the `RunConfig`:"
      ]
    },
    {
      "metadata": {
        "id": "PyJ7CSIFuOce",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "strategy = tf.contrib.distribute.MirroredStrategy()\n",
        "config = tf.estimator.RunConfig(train_distribute=strategy)\n",
        "\n",
        "estimator = tf.keras.estimator.model_to_estimator(model, config=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YeLx5wLBuOcl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create an Estimator input function\n",
        "\n",
        "To pipe data into Estimators we need to define a data importing function like shown below which returns batches of `(images, labels)` as shown below:"
      ]
    },
    {
      "metadata": {
        "id": "i1J7vV9_uOcm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def input_fn(images, labels, repeat, batch_size):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    SHUFFLE_SIZE = 10000\n",
        "    dataset = dataset.shuffle(SHUFFLE_SIZE).repeat(repeat).batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JD_91nB7uOcn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Estimator\n",
        "\n",
        "Now the good part! We can call the `train` function on our estimator giving it `input_fn` we defined as well as the number of steps of the optimizer we wish to run:"
      ]
    },
    {
      "metadata": {
        "id": "dg7pxlTQuOco",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=128\n",
        "EPOCHS=5\n",
        "STEPS = 1000\n",
        "\n",
        "estimator.train(input_fn=lambda:input_fn(train_images,\n",
        "                                         train_labels,\n",
        "                                         repeat=EPOCHS,\n",
        "                                         batch_size=BATCH_SIZE), \n",
        "                steps=STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wcYcu1mTuOcs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Estimator\n",
        "\n",
        "In order to check the performance of our model we can then run the `evaluate` method on our Estimator:"
      ]
    },
    {
      "metadata": {
        "id": "zMbzl2FAuOct",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "estimator.evaluate(input_fn=lambda:input_fn(test_images, test_labels, repeat=1, batch_size=BATCH_SIZE), steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}