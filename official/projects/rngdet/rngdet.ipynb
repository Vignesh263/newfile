{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# RNGDet evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2FlaQcEPOER"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install and import the necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
        "\n",
        "#import sys\n",
        "#sys.path.append(\"/mnt/hdd-nfs-intern/ghpark/03_temp/models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHT1iiIiBzlC"
      },
      "outputs": [],
      "source": [
        "from official.projects.rngdet.tasks import rngdet\n",
        "from official.core import exp_factory\n",
        "exp_config = exp_factory.get_exp_config('rngdet_cityscale')\n",
        "task_obj = rngdet.RNGDetTask(exp_config.task)\n",
        "model = task_obj.build_model()\n",
        "#task_obj.initialize(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ckpt_dir_or_file = '/mnt/hdd-nfs-intern/ghpark/03_temp/ckpt/test_10'\n",
        "ckpt = tf.train.Checkpoint(\n",
        "    backbone=model.backbone,\n",
        "    backbone_history=model.backbone_history,\n",
        "    transformer=model.transformer,\n",
        "    segment_fpn=model._segment_fpn,\n",
        "    keypoint_fpn=model._keypoint_fpn,\n",
        "    query_embeddings=model._query_embeddings,\n",
        "    segment_head=model._segment_head,\n",
        "    keypoint_head=model._keypoint_head,\n",
        "    class_embed=model._class_embed,\n",
        "    bbox_embed=model._bbox_embed,\n",
        "    input_proj=model.input_proj)\n",
        "status = ckpt.restore(tf.train.latest_checkpoint(ckpt_dir_or_file))\n",
        "status.expect_partial().assert_existing_objects_matched()\n",
        "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
        "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
        "print(\"LOAD CHECKPOINT DONE\")\n",
        "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
        "print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from official.projects.rngdet.eval import agent\n",
        "\n",
        "pad_size = 128\n",
        "sat_image = np.array(Image.open(os.path.join('./region_0_sat.png')))\n",
        "\n",
        "sat_image = tf.cast(sat_image, tf.float32)\n",
        "agent = agent.Agent(model, sat_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logit_threshold = 0.75\n",
        "roi_size = 128\n",
        "\n",
        "while 1:\n",
        "    agent.step_counter += 1\n",
        "    # crop ROI\n",
        "    sat_ROI, historical_ROI = agent.crop_ROI(agent.current_coord)\n",
        "    sat_ROI = tf.expand_dims(sat_ROI, 0) / 255.0\n",
        "    # (gunho) historical_ROI / 255.0 in original code\n",
        "    historical_ROI = tf.expand_dims(historical_ROI, 0) / 255.0\n",
        "    historical_ROI = tf.expand_dims(historical_ROI, -1)\n",
        "    historical_ROI = tf.cast(historical_ROI, tf.float32)\n",
        "    # predict vertices in the next step\n",
        "    outputs, pred_segment, pred_keypoint = model(sat_ROI, historical_ROI, training=False)\n",
        "    # agent moves\n",
        "    # alignment vertices\n",
        "    outputs = outputs[-1]\n",
        "    pred_coords = outputs['box_outputs']\n",
        "    pred_probs = outputs['cls_outputs']\n",
        "    alignment_vertices = [[v[0]-agent.current_coord[0]+agent.crop_size//2,\n",
        "        v[1]-agent.current_coord[1]+agent.crop_size//2] for v in agent.historical_vertices]\n",
        "    pred_coords_ROI = agent.step(pred_probs,pred_coords,thr=logit_threshold)\n",
        "    \n",
        "    if agent.finish_current_image:\n",
        "        print(f'STEP 3: Finsh exploration. Save visualization and graph...')\n",
        "        Image.fromarray(\n",
        "            agent.historical_map[roi_size:-roi_size,roi_size:-roi_size].astype(np.uint8)\n",
        "            ).convert('RGB').save(f'./segmentation/0_result.png')\n",
        "        break\n",
        "    # stop action\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TEMP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a8582ebde7b"
      },
      "source": [
        "Use `ds_info` (which is an instance of `tfds.core.DatasetInfo`) to lookup the text descriptions of each class ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDys5bZ1zsml"
      },
      "source": [
        "Run a batch of the processed training data through the model, and view the results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "classification_with_model_garden.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
